{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c18653-9acf-4aa5-9800-76dadb55a338",
   "metadata": {},
   "source": [
    "# Amazon Bedrock - Latency Benchmark Tool\n",
    "This notebook contains a set of tools to benchmark inference latency for Foundation Models available in Amazon Bedrock. \n",
    "\n",
    "You can evaluate latency for different scenarios such as comparison between use cases, regions, and models, including models from 3rd-party platforms like OpenAI's GPT-4.\n",
    "\n",
    "To run this notebook you will need to have the appropriate access to Amazon Bedrock, and previously enabled the models from the Amazon Bedrock Console. \n",
    "\n",
    "## Examples included in this notebook\n",
    "1. [Use Case Comparison](#uc-compare) - Compare the latency of a given model across different LLM use cases (e.g., Summarization and classification).\n",
    "2. [Region Comparison](#region-compare) - Comparing latency between two different models.\n",
    "3. [Model Comparison](#model-compare) - Comparing the latency of a given model across different AWS regions.\n",
    "\n",
    "### Install needed dependencies\n",
    "Note: This notebook requires a basic Python 3 environment (e.g, `Base Python 3.0` in SageMaker Studio Notebooks)\n",
    "\n",
    "### API key\n",
    "\n",
    "- Create a new file called `utils/key.py` in your project directory to store your API key.\n",
    "\n",
    "- Do **not** commit `key.py` to source control, as it contains sensitive information. **Add `*key.py` to `.gitgnore`.** Review [this information about API safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety).\n",
    "\n",
    "- Go to your OpenAI account and navigate to \"[View API keys](https://platform.openai.com/account/api-keys).\"\n",
    "\n",
    "- Select \"Create new secret key.\"\n",
    "\n",
    "- Copy the key and insert it into your file `utils/key.py` like this:\n",
    "```\n",
    "OPENAI_API_KEY = 'sk-actualLongKeyGoesHere123'\n",
    "```\n",
    "\n",
    "- Save the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b39d1-be17-4c26-afc9-9718ac0c4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade pip\n",
    "!pip install --quiet --upgrade boto3 awscli matplotlib numpy pandas nbdime anthropic openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ae496-c922-446d-9928-b49abf2439c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.utils import benchmark, create_prompt, execute_benchmark, get_cached_client, post_iteration, graph_scenarios_boxplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233b6f7-1996-4fa5-8378-6e88bd64cd73",
   "metadata": {},
   "source": [
    "## Scenario keys and configurations\n",
    "\n",
    "Each scenario is a dictionary with latency relevant keys:\n",
    "\n",
    "| Key | Definition |\n",
    "|-|-|\n",
    "| `model_id` | The Bedrock model_id (like `anthropic.claude-v2`) or OpenAI model name (like `gpt-4-1106-preview`) to test. Smaller models are likely faster. Currently only Anthropic and OpenAI's GPT models are supported. |\n",
    "| `in_tokens` | The number of tokens to feed to the model (input context length). The range depends on the model_id. For example: 40 - 100K for Claude-2. |\n",
    "| `out_tokens` | The number of tokens for the model to generate. Range: 1 - 8191. |\n",
    "| `region` | The AWS region to invoke Bedrock in. This can affect network latency depending on client location. |\n",
    "| `stream` | True&#124;False - A streaming response starts returning tokens to the client as they are generated, instead of waiting before returning the complete responses. This should be True for interactive use cases.|\n",
    "| `name` | A human readable name for the scenario (will appear in reports and graphs). |\n",
    "\n",
    "Each scenario also has a benchmark configuration you can modify:\n",
    "\n",
    "| Key | Definition |\n",
    "|-|-|\n",
    "| `invocations_per_scenario` | The number of times to benchmark each scenario. This is important in measuring variance and average response time across a long duration. |\n",
    "| `sleep_between_invocations` | Seconds to sleep between each invocation. (0 is no sleep). Sleeping between invocation can help you measure across longer periods of time, and/or avoid throttling.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870dd288",
   "metadata": {},
   "source": [
    "## Example 1. Simulated LLM Use Case Performance Analysis\n",
    "<a id=\"uc-compare\"></a>\n",
    "\n",
    "This section illustrates a comparative analysis of model latency in simulated LLM scenarios. Rather than actual prompt engineering, we use token count variations to represent different use cases. Here's how:\n",
    "\n",
    "1. **Simulated Summarization Scenario**: This mimics a scenario where a lengthy input is condensed into a brief summary. We simulate this with 2000 `in_tokens` for input and 200 `out_tokens` for output.\n",
    "\n",
    "2. **Simulated Classification Scenario**: Here, the scenario represents processing a medium to lengthy input to categorize into a single class. For simulation, it involves 400 `in_tokens` and just 1 `out_token`.\n",
    "\n",
    "These scenarios are adjustable to align with your specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ad5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cases_scenarios = [\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-v2',\n",
    "                'in_tokens'  : 2000,\n",
    "                'out_tokens' : 200,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'Summarization. in=2000, out=200',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-v2',\n",
    "                'in_tokens' : 400,\n",
    "                'out_tokens' : 1,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'Classification. in=400, out=1',\n",
    "            }\n",
    "]\n",
    "\n",
    "scenario_config = {\n",
    "    \"invocations_per_scenario\" : 2,\n",
    "    \"sleep_between_invocations\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = execute_benchmark(use_cases_scenarios, scenario_config, early_break = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9a92c",
   "metadata": {},
   "source": [
    "#### Analyze results \n",
    "The results show should show that summarization has a higher latency than classification due to the smaller number of input and output tokens.  \n",
    "Note: Learn more on how to read boxplots [here](https://builtin.com/data-science/boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scenarios_boxplot(\n",
    "    scenarios=scenarios, \n",
    "    title=\"Use Cases Comparison\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c14d81-e230-4a7b-bb9c-6aae36d23740",
   "metadata": {},
   "source": [
    "## Example 2. Model Comparison\n",
    "<a id=\"model-compare\"></a>\n",
    "Here we'll be comparing the latency of two different models: `anthropic.claude-v2` and `anthropic.claude-instant-v1`. We expect `anthropic.claude-v2` to be slower as it is a bigger, more capable and more expensive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76398a-06cc-4854-b726-a9e09e10905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare_scenarios = [\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-v2',\n",
    "                'in_tokens'  : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-instant-v1',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'gpt-4-1106-preview',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : True\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'gpt-4-1106-preview',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : False\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'ai21.j2-ultra-v1',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : False\n",
    "            }\n",
    "]\n",
    "\n",
    "scenario_config = {\n",
    "    \"invocations_per_scenario\" : 2,\n",
    "    \"sleep_between_invocations\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198a77d-7087-4cd8-8877-d44df4ad5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = execute_benchmark(model_compare_scenarios, scenario_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2e495-dde6-46d1-9061-fb8c5751d781",
   "metadata": {},
   "source": [
    "### Results\n",
    "Results show show that claude-instant-v1 is faster than Claude-v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921f2dc-86d3-4b59-b88b-22ce604084a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scenarios_boxplot(\n",
    "    scenarios=scenarios, \n",
    "    title=\"Model Comparison\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110537c-aab1-484e-b57f-f0d340e38707",
   "metadata": {},
   "source": [
    "\n",
    "## Example 3. Region Comparison\n",
    "<a id=\"region-compare\"></a>\n",
    "Here we'll be comparing the latency of a given model_id across three different AWS regions. Different regions resides in different timezone, and the load on each region can depend on the time of day.\n",
    "> **ðŸš¨ ALERT ðŸš¨** Remember to enable the models in **all regions** you wish to test. \n",
    "You can learn how to manage model access in the following [page](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html#manage-model-access).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756c1dd-0f54-4def-b5f5-6f1eed29e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_compare_scenarios = [\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-instant-v1',\n",
    "                'in_tokens'  : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'us-east-1',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-instant-v1',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'us-west-2',\n",
    "                'stream' : True,\n",
    "                'name' : f'us-west-2',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-instant-v1',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'eu-central-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'eu-central-1',\n",
    "            }\n",
    "]\n",
    "\n",
    "scenario_config = {\n",
    "    \"invocations_per_scenario\" : 2,\n",
    "    \"sleep_between_invocations\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b433f-a1f6-4655-ab85-1f4e7fd7e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = execute_benchmark(region_compare_scenarios, scenario_config, early_break = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47558c5-e64b-4e5d-a628-d3892468eb08",
   "metadata": {},
   "source": [
    "### Results\n",
    "We don't apriori expect a particular region to be faster than others in a significant way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aeffe9-cecb-4b78-b179-cfb2a1c15e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scenarios_boxplot(\n",
    "    scenarios=scenarios, \n",
    "    title=\"Regions Comparison\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6a9ce",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
