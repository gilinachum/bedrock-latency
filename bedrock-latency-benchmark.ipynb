{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c18653-9acf-4aa5-9800-76dadb55a338",
   "metadata": {},
   "source": [
    "# Amazon Bedrock - Latency Benchmark Tool\n",
    "This notebook contains a set of tools to benchmark inference latency for Foundation Models available in Amazon Bedrock. It supports Claude 3 models using the messaging API.\n",
    "\n",
    "You can evaluate latency for different scenarios such as comparison between use cases, regions, and models, including models from 3rd-party platforms like OpenAI's GPT-4.\n",
    "\n",
    "To run this notebook you will need to have the appropriate access to Amazon Bedrock, and previously enabled the models from the Amazon Bedrock Console. \n",
    "\n",
    "## Examples included in this notebook\n",
    "1. [Use Case Comparison](#uc-compare) - Compare the latency of a given model across different LLM use cases (e.g., Summarization and classification).\n",
    "2. [Model Comparison](#model-compare) - Comparing the latency of a given model across different AWS regions.\n",
    "3. [Region Comparison](#region-compare) - Comparing latency between two different models.\n",
    "\n",
    "### Install needed dependencies\n",
    "Note: This notebook requires a basic Python 3 environment (e.g, `Base Python 3.0` in SageMaker Studio Notebooks)\n",
    "\n",
    "### Create OpenAI API key (if measuring OpenAI models)\n",
    "\n",
    "- Create a new file called `utils/key.py` in your project directory to store your API key.\n",
    "\n",
    "- Do **not** commit `key.py` to source control, as it contains sensitive information. **Add `*key.py` to `.gitgnore`.** Review [this information about API safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety).\n",
    "\n",
    "- Go to your OpenAI account and navigate to \"[View API keys](https://platform.openai.com/account/api-keys).\"\n",
    "\n",
    "- Select \"Create new secret key.\"\n",
    "\n",
    "- Copy the key and insert it into your file `utils/key.py` like this:\n",
    "```\n",
    "OPENAI_API_KEY = 'sk-actualLongKeyGoesHere123'\n",
    "```\n",
    "\n",
    "- Save the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b39d1-be17-4c26-afc9-9718ac0c4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade pip\n",
    "!pip install --quiet --upgrade boto3 awscli matplotlib numpy pandas nbdime anthropic openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ae496-c922-446d-9928-b49abf2439c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('utils.utils')\n",
    "logger.setLevel(logging.INFO) # <-- Change to DEBUG to troubleshoot errors\n",
    "\n",
    "from utils.utils import benchmark, create_prompt, execute_benchmark, get_cached_client, post_iteration, graph_scenarios_boxplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233b6f7-1996-4fa5-8378-6e88bd64cd73",
   "metadata": {},
   "source": [
    "## Scenario keys and configurations\n",
    "\n",
    "Each scenario is a dictionary with latency relevant keys:\n",
    "\n",
    "| Key | Definition |\n",
    "|-|-|\n",
    "| `model_id` | The Bedrock model_id (like `anthropic.claude-v2`) or OpenAI model name (like `gpt-4-1106-preview`) to test. Smaller models are likely faster. Currently only Anthropic and OpenAI's GPT models are supported. |\n",
    "| `in_tokens` | The number of tokens to feed to the model (input context length). The range depends on the model_id. For example: 40 - 100K for Claude-2. |\n",
    "| `out_tokens` | The number of tokens for the model to generate. Range: 1 - 8191. |\n",
    "| `region` | The AWS region to invoke Bedrock in. This can affect network latency depending on client location. |\n",
    "| `stream` | True&#124;False - A streaming response starts returning tokens to the client as they are generated, instead of waiting before returning the complete responses. This should be True for interactive use cases.|\n",
    "| `name` | A human readable name for the scenario (will appear in reports and graphs). |\n",
    "\n",
    "Each scenario also has a benchmark configuration you can modify:\n",
    "\n",
    "| Key | Definition |\n",
    "|-|-|\n",
    "| `invocations_per_scenario` | The number of times to benchmark each scenario. This is important in measuring variance and average response time across a long duration. |\n",
    "| `sleep_between_invocations` | Seconds to sleep between each invocation. (0 is no sleep). Sleeping between invocation can help you measure across longer periods of time, and/or avoid throttling.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870dd288",
   "metadata": {},
   "source": [
    "## Example 1. Simulated LLM Use Case Performance Analysis\n",
    "<a id=\"uc-compare\"></a>\n",
    "\n",
    "This section illustrates a comparative analysis of model latency in simulated LLM scenarios. Rather than actual prompt engineering, we use token count variations to represent different use cases. Here's how:\n",
    "\n",
    "1. **Simulated Summarization Scenario**: This mimics a scenario where a lengthy input is condensed into a brief summary. We simulate this with 2000 `in_tokens` for input and 200 `out_tokens` for output.\n",
    "\n",
    "2. **Simulated Classification Scenario**: Here, the scenario represents processing a medium to lengthy input to categorize into a single class. For simulation, it involves 400 `in_tokens` and just 1 `out_token`.\n",
    "\n",
    "These scenarios are adjustable to align with your specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ad5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cases_scenarios = [\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "                'in_tokens'  : 2000,\n",
    "                'out_tokens' : 200,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'Summarization',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "                'in_tokens' : 400,\n",
    "                'out_tokens' : 1,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'Classification',\n",
    "            }\n",
    "]\n",
    "\n",
    "scenario_config = {\n",
    "    \"invocations_per_scenario\" : 2,\n",
    "    \"sleep_between_invocations\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = execute_benchmark(use_cases_scenarios, scenario_config, early_break = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9a92c",
   "metadata": {},
   "source": [
    "#### Analyze results \n",
    "The results show should show that summarization has a higher latency than classification due to the smaller number of input and output tokens.  \n",
    "Note: Learn more on how to read boxplots [here](https://builtin.com/data-science/boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scenarios_boxplot(\n",
    "    scenarios=scenarios, \n",
    "    title=\"Use Cases Comparison over Same model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c14d81-e230-4a7b-bb9c-6aae36d23740",
   "metadata": {},
   "source": [
    "## Example 2. Model Comparison\n",
    "<a id=\"model-compare\"></a>\n",
    "Here we'll be comparing the latency of these models: \n",
    "- Bedrock\n",
    "    - `anthropic.claude-3-sonnet` \n",
    "    - `anthropic.claude-3-haiku`\n",
    "    - `amazon.titan-text-express-v1`\n",
    "- OpenAI\n",
    "    - `gpt-4`\n",
    "    - `gpt-4-1106-preview`\n",
    "    - `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76398a-06cc-4854-b726-a9e09e10905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare_scenarios = [\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "                'in_tokens'  : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'claude-3-Sonnet',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'claude-3-Haiku',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'gpt-4',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : True,\n",
    "                'name' : f'gpt-4',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'gpt-4-1106-preview',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : True,\n",
    "                'name' : f'gpt-4-turbo',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'gpt-3.5-turbo',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : True,\n",
    "                'name' : f'gpt-3.5-turbo',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'amazon.titan-text-express-v1', # or us a fine tuned model arn\n",
    "                'in_tokens'  : 200,\n",
    "                'out_tokens' : 5,\n",
    "                'region'     : 'us-east-1',\n",
    "                'stream' : True,\n",
    "                'name' : f'titan',\n",
    "            },\n",
    "]\n",
    "\n",
    "scenario_config = {\n",
    "    \"invocations_per_scenario\" : 3,\n",
    "    \"sleep_between_invocations\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76fb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = execute_benchmark(model_compare_scenarios, scenario_config, early_break = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2e495-dde6-46d1-9061-fb8c5751d781",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921f2dc-86d3-4b59-b88b-22ce604084a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scenarios_boxplot(\n",
    "    scenarios=scenarios, \n",
    "    title=\"Model Comparison\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110537c-aab1-484e-b57f-f0d340e38707",
   "metadata": {},
   "source": [
    "\n",
    "## Example 3. Region Comparison\n",
    "<a id=\"region-compare\"></a>\n",
    "Here we'll be comparing the latency of a given model_id across three different AWS regions. Different regions resides in different timezone, and the load on each region can depend on the time of day.\n",
    "> **🚨 ALERT 🚨** Remember to enable the models in **all regions** you wish to test. \n",
    "You can learn how to manage model access in the following [page](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html#manage-model-access).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756c1dd-0f54-4def-b5f5-6f1eed29e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_compare_scenarios = [\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : True,\n",
    "                'name' : f'us-east-1: claude-3-Haiku',\n",
    "                'region'     : 'us-east-1',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : True,\n",
    "                'name' : f'us-west-2: claude-3-Haiku',\n",
    "                'region' : f'us-west-2',\n",
    "            },\n",
    "            {\n",
    "                'model_id'    : 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "                'in_tokens' : 200,\n",
    "                'out_tokens' : 50,\n",
    "                'stream' : True,\n",
    "                'name' : f'eu-central-1: claude-3-Haiku',\n",
    "                'region' : f'eu-central-1',\n",
    "            },\n",
    "]\n",
    "\n",
    "scenario_config = {\n",
    "    \"invocations_per_scenario\" : 2,\n",
    "    \"sleep_between_invocations\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b433f-a1f6-4655-ab85-1f4e7fd7e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = execute_benchmark(region_compare_scenarios, scenario_config, early_break = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47558c5-e64b-4e5d-a628-d3892468eb08",
   "metadata": {},
   "source": [
    "### Results\n",
    "We don't apriori expect a particular region to be faster than others in a significant way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aeffe9-cecb-4b78-b179-cfb2a1c15e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_scenarios_boxplot(\n",
    "    scenarios=scenarios, \n",
    "    title=\"Regions Comparison\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6a9ce",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
